apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: kfto-demo
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: Never
      template:
        spec:
          containers:
            - env:
                - name: SFT_TRAINER_CONFIG_JSON_PATH
                  value: /etc/config/config.json
                - name: SET_NUM_PROCESSES_TO_NUM_GPUS
                  value: "false"
                - name: TORCH_NCCL_ASYNC_ERROR_HANDLING
                  value: "1"
                - name: PYTORCH_CUDA_ALLOC_CONF
                  value: "expandable_segments:True"
              image: 'quay.io/jishikaw/fms-hf-tuning:latest'
              imagePullPolicy: IfNotPresent
              name: pytorch
              ports:
                - containerPort: 29500
                  name: pytorchjob-port
              resources:
                limits:
                  nvidia.com/gpu: 1
              volumeMounts:
                - mountPath: /etc/config
                  name: config-volume
                - mountPath: /data/input
                  name: dataset-volume
                - mountPath: /data/output
                  name: model-volume
                - mountPath: /.cache
                  name: cache-volume
                - mountPath: "/dev/shm"
                  name: dshm
          volumes:
            - configMap:
                items:
                  - key: config.json
                    path: config.json
                name: training-config
              name: config-volume
            - persistentVolumeClaim:
                claimName: dataset-volume
              name: dataset-volume
            - name: model-volume
              persistentVolumeClaim:
                claimName: model-volume
            - name: cache-volume
              persistentVolumeClaim:
                claimName: cache-volume
            - name: dshm
              emptyDir:
                medium: Memory
    Worker:
      replicas: 1
      restartPolicy: Never
      template:
        spec:
          containers:
            - env:
                - name: SFT_TRAINER_CONFIG_JSON_PATH
                  value: /etc/config/config.json
                - name: SET_NUM_PROCESSES_TO_NUM_GPUS
                  value: "false"
                - name: TORCH_NCCL_ASYNC_ERROR_HANDLING
                  value: "1"
                - name: PYTORCH_CUDA_ALLOC_CONF
                  value: "expandable_segments:True"
              image: 'quay.io/jishikaw/fms-hf-tuning:latest'
              imagePullPolicy: IfNotPresent
              name: pytorch
              ports:
                - containerPort: 29500
                  name: pytorchjob-port
              resources:
                limits:
                  nvidia.com/gpu: 1
              volumeMounts:
                - mountPath: /etc/config
                  name: config-volume
                - mountPath: /data/input
                  name: dataset-volume
                - mountPath: /data/output
                  name: model-volume
                - mountPath: /.cache
                  name: cache-volume
                - mountPath: "/dev/shm"
                  name: dshm
          volumes:
            - configMap:
                items:
                  - key: config.json
                    path: config.json
                name: training-config
              name: config-volume
            - persistentVolumeClaim:
                claimName: dataset-volume
              name: dataset-volume
            - name: model-volume
              persistentVolumeClaim:
                claimName: model-volume
            - name: cache-volume
              persistentVolumeClaim:
                claimName: cache-volume
            - name: dshm
              emptyDir:
                medium: Memory
  runPolicy:
    suspend: false

